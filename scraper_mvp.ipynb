{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89b6f2c-832e-4497-82ee-9e30cef21698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca199a2-35a9-4bdd-8e48-8e48af92e953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter start year:  1993\n",
      "Enter end year:  2023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data scraped for 1993\n",
      "Data scraped for 1994\n",
      "Data scraped for 1995\n",
      "Data scraped for 1996\n",
      "Data scraped for 1997\n"
     ]
    }
   ],
   "source": [
    "def scrape_baseball_reference(url, writer):\n",
    "    response = requests.get(url) #Get HTML\n",
    "    if response.status_code != 200:\n",
    "        print(\"Failed to fetch page\")\n",
    "        return\n",
    "    soup = BeautifulSoup(response.text, 'html.parser') #Parse HTML\n",
    "\n",
    "    # Find AL MVP table\n",
    "    al_mvp_table = soup.find('table', {'id': 'AL_MVP_voting'})\n",
    "    if al_mvp_table:\n",
    "        scrape_table(al_mvp_table, writer, url)\n",
    "\n",
    "    # Find NL MVP table\n",
    "    nl_mvp_table = soup.find('table', {'id': 'NL_MVP_voting'})\n",
    "    if nl_mvp_table:\n",
    "        scrape_table(nl_mvp_table, writer, url)\n",
    "\n",
    "def scrape_table(table, writer, year_url):\n",
    "    year = year_url.split('_')[-1].split('.')[0]  # Extract year from URL\n",
    "    for tr in table.find_all('tr')[1:]: # Find tables\n",
    "        row_data = [year]  # Add year as the first element\n",
    "        row_data.extend(td.text.strip() for td in tr.find_all('td'))\n",
    "        writer.writerow(row_data)\n",
    "\n",
    "def gen_base_urls(start_yr, end_yr): # Generates base urls to scrape\n",
    "    base_urls = []\n",
    "    for year in range(start_yr, end_yr + 1):\n",
    "        base_url = f\"https://www.baseball-reference.com/awards/awards_{year}.shtml\"\n",
    "        base_urls.append(base_url)\n",
    "    return base_urls\n",
    "\n",
    "# User inputs\n",
    "start_year = int(input(\"Enter start year: \"))\n",
    "end_year = int(input(\"Enter end year: \"))\n",
    "output_file = f'mvp_voting_{start_year}_{end_year}.csv'\n",
    "\n",
    "# Write csv\n",
    "with open(output_file, 'w', newline='', encoding='utf-8') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    column_headers = [\"Year\", \"Name\", \"Tm\", \"Vote Pts\", \"1st Place\", \"Share\", \"WAR\", \"G\", \"AB\", \"R\", \"H\", \"HR\", \"RBI\", \"SB\", \"BB\", \"BA\", \"OBP\", \"SLG\", \"OPS\", \"W\", \"L\", \"ERA\", \"WHIP\", \"G\", \"GS\", \"SV\", \"IP\", \"H\", \"HR\", \"BB\", \"SO\"]\n",
    "    writer.writerow(column_headers)\n",
    "\n",
    "    base_urls = gen_base_urls(start_year,end_year)\n",
    "    \n",
    "    # Scraping each year\n",
    "    for base_url in base_urls:\n",
    "        scrape_baseball_reference(base_url, writer)\n",
    "        year = base_url.split('_')[-1].split('.')[0]\n",
    "        print(f\"Data scraped for {year}\")\n",
    "\n",
    "        time.sleep(2)  # Avoiding being flagged"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
